mean(Precision.Yes)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
d1.lda=lda(pass_fail~.-id-G3-G2-G1-pass_fail-grades, data = d1.train)
d1.pred <- predict(d1.lda,newdata = d1.test)
perform <- table(d1.pred$class, d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
# LDA
library(MASS)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
d1.lda=lda(pass_fail~.-id-G3-G1-pass_fail-grades, data = d1.train)
d1.pred <- predict(d1.lda,newdata = d1.test)
perform <- table(d1.pred$class, d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(e1071)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
model.nb <- naiveBayes(pass_fail~.-id-G3-pass_fail-grades, data = d1.train)
pred.nb <- predict(model.nb, newdata = d1.test)
perform <- table(pred.nb, d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
model.nb <- naiveBayes(pass_fail~.-id-G3-G2-pass_fail-grades, data = d1.train)
pred.nb <- predict(model.nb, newdata = d1.test)
perform <- table(pred.nb, d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(e1071)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
model.nb <- naiveBayes(pass_fail~.-id-G3-G2-G1-pass_fail-grades, data = d1.train)
pred.nb <- predict(model.nb, newdata = d1.test)
perform <- table(pred.nb, d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(tree)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
tree.d2=tree(pass_fail~.-id-G3-G1-pass_fail-grades,d2.train)
tree.pred=predict(tree.d2,d2.test,type="class")
perform <- table(tree.pred, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(tree)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
tree.d2=tree(pass_fail~.-id-G3-pass_fail-grades,d2.train)
tree.pred=predict(tree.d2,d2.test,type="class")
perform <- table(tree.pred, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(tree)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
tree.d1=tree(pass_fail~.-id-G3-pass_fail-grades,d1.train)
tree.pred=predict(tree.d1,d1.test,type="class")
perform <- table(tree.pred, d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
tree.d1=tree(pass_fail~.-id-G3-G2-G1-pass_fail-grades,d1.train)
tree.pred=predict(tree.d1,d1.test,type="class")
perform <- table(tree.pred, d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
d1$pass_fail = ifelse(d1$G3>=10,0,1)
library(gbm)
#Boosting
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
d1.boosting=gbm(pass_fail~.-id-G3-G1-pass_fail-grades,data = d1.train,distribution="bernoulli",n.trees=5000,interaction.depth=4)
boost.probs=predict(d1.boosting,newdata=d1.test,type="response",n.trees=5000)
boost.pred=rep(0,dim(d1.test)[1])
boost.pred[boost.probs>=0.5]=1
perform <- table(boost.pred,d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(gbm)
#Boosting
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
d1.boosting=gbm(pass_fail~.-id-G3-pass_fail-grades,data = d1.train,distribution="bernoulli",n.trees=5000,interaction.depth=4)
boost.probs=predict(d1.boosting,newdata=d1.test,type="response",n.trees=5000)
boost.pred=rep(0,dim(d1.test)[1])
boost.pred[boost.probs>=0.5]=1
perform <- table(boost.pred,d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(gbm)
#Boosting
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
d1.boosting=gbm(pass_fail~.-id-G3-G2-G1-pass_fail-grades,data = d1.train,distribution="bernoulli",n.trees=5000,interaction.depth=4)
boost.probs=predict(d1.boosting,newdata=d1.test,type="response",n.trees=5000)
boost.pred=rep(0,dim(d1.test)[1])
boost.pred[boost.probs>=0.5]=1
perform <- table(boost.pred,d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
set.seed(123)
setwd("D:/Git/Student-Predictive-Modelling/student")
d1=read.table("student-mat.csv",sep=";",header=TRUE)
d2=read.table("student-por.csv",sep=";",header=TRUE)
d1.length = dim(d1)[1]
id = 1:d1.length
pass_fail = as.factor(d1$G3 >= 10)
d1 = data.frame(id,d1,pass_fail)
d1$grades <- cut(d1$G3, breaks=c(-1,9,11,13,15,20),labels=c("F","D","C","B","A"))
colnames(d1)
sapply(d1,class)
d2.length = dim(d2)[1]
id = 1:d2.length
pass_fail = as.factor(d2$G3 >= 10)
d2 = data.frame(id,d2,pass_fail)
d2$grades <- cut(d2$G3, breaks=c(-1,9,11,13,15,20),labels=c("F","D","C","B","A"))
colnames(d2)
sapply(d2,class)
nfolds = 5
foldPosition = sample(rep(1:nfolds, length.out = dim(d2)[1]))
Accuracy = replicate(nfolds,0)
Recall.No = replicate(nfolds,0)
Recall.Yes = replicate(nfolds,0)
Precision.No = replicate(nfolds,0)
Precision.Yes = replicate(nfolds,0)
library(e1071)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
model.nb <- naiveBayes(pass_fail~.-id-G3-G2-G1-pass_fail-grades, data = d2.train)
pred.nb <- predict(model.nb, newdata = d2.test)
perform <- table(pred.nb, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(e1071)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
model.nb <- naiveBayes(pass_fail~.-id-G3-pass_fail-grades, data = d2.train)
pred.nb <- predict(model.nb, newdata = d2.test)
perform <- table(pred.nb, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(tree)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
tree.d2=tree(pass_fail~.-id-G3-G2-G1-pass_fail-grades,d2.train)
tree.pred=predict(tree.d2,d2.test,type="class")
perform <- table(tree.pred, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(tree)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
tree.d2=tree(pass_fail~.-id-G3-pass_fail-grades,d2.train)
tree.pred=predict(tree.d2,d2.test,type="class")
perform <- table(tree.pred, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
# LDA
library(MASS)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
d2.lda=lda(pass_fail~.-id-G3-G1-pass_fail-grades, data = d2.train)
d2.pred <- predict(d2.lda,newdata = d2.test)
perform <- table(d2.pred$class, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
# LDA
library(MASS)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
d2.lda=lda(pass_fail~.-id-G3-pass_fail-grades, data = d2.train)
d2.pred <- predict(d2.lda,newdata = d2.test)
perform <- table(d2.pred$class, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(MASS)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
d2.lda=lda(pass_fail~.-id-G3-G2-G1-pass_fail-grades, data = d2.train)
d2.pred <- predict(d2.lda,newdata = d2.test)
perform <- table(d2.pred$class, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
d2$pass_fail = ifelse(d2$G3>=10,0,1)
library(gbm)
#Boosting
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
d2.boosting=gbm(pass_fail~.-id-G3-G2-G1-pass_fail-grades,data = d2.train,distribution="bernoulli",n.trees=5000,interaction.depth=4)
boost.probs=predict(d2.boosting,newdata=d2.test,type="response",n.trees=5000)
boost.pred=rep(0,dim(d2.test)[1])
boost.pred[boost.probs>=0.5]=1
perform <- table(boost.pred,d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
library(gbm)
#Boosting
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
d2.boosting=gbm(pass_fail~.-id-G3-pass_fail-grades,data = d2.train,distribution="bernoulli",n.trees=5000,interaction.depth=4)
boost.probs=predict(d2.boosting,newdata=d2.test,type="response",n.trees=5000)
boost.pred=rep(0,dim(d2.test)[1])
boost.pred[boost.probs>=0.5]=1
perform <- table(boost.pred,d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
d2.length = dim(d2)[1]
d2=read.table("student-por.csv",sep=";",header=TRUE)
d2.length = dim(d2)[1]
id = 1:d2.length
pass_fail = as.factor(d2$G3 >= 10)
d2 = data.frame(id,d2,pass_fail)
d2$grades <- cut(d2$G3, breaks=c(-1,9,11,13,15,20),labels=c("F","D","C","B","A"))
library(BBmisc)
d2$age <- normalize(d2$age, method="standardize")
d2$absences <- normalize(d2$absences, method="standardize")
d2$G1 <- normalize(d2$G1, method="standardize")
d2$G2 <- normalize(d2$G2, method="standardize")
library(kknn)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
d2.kknn = kknn(pass_fail~.-id-G3-G1-pass_fail-grades, d2.train, d2.test, k=12)
fit = fitted(d2.kknn)
perform <- table(fit, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
remove(d2.kknn)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
d2.kknn = kknn(pass_fail~.-id-G3-pass_fail-grades, d2.train, d2.test, k=12)
fit = fitted(d2.kknn)
perform <- table(fit, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
remove(d2.kknn)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d2.test = d2[test_i,]
d2.train = d2[-test_i,]
d2.kknn = kknn(pass_fail~.-id-G3-G2-G1-pass_fail-grades, d2.train, d2.test, k=12)
fit = fitted(d2.kknn)
perform <- table(fit, d2.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
mean(Recall.Yes)
mean(Recall.No)
mean(Precision.No)
mean(Precision.Yes)
remove(d2.kknn)
