Bike <- c(10,31,43,16,11,33,45,17,13,34,48,19,15,37,51,21)
Yt <- ts(Bike, frequency=4) #function “ts” is used to create time series
object
Yt
plot(Yt, xlab="Time", ylab="Sales", col="Blue")
m<- HoltWinters(Yt, alpha=0.2, beta=0.1, gamma=0.1, seasonal="additive")
m
MSE <- m$"SSE"/(NROW(Bike)-3)
MSE
Bike <- c(10,31,43,16,11,33,45,17,13,34,48,19,15,37,51,21)
Yt <- ts(Bike, frequency=4) #function “ts” is used to create time series
Yt
plot(Yt, xlab="Time", ylab="Sales", col="Blue")
m<- HoltWinters(Yt, alpha=0.2, beta=0.1, gamma=0.1, seasonal="additive")
m
MSE <- m$"SSE"/(NROW(Bike)-3)
MSE
Bike <- c(10,31,43,16,11,33,45,17,13,34,48,19,15,37,51,21)
Yt <- ts(Bike, frequency=4) #function “ts” is used to create time series
Yt
plot(Yt, xlab="Time", ylab="Sales", col="Blue")
m<- HoltWinters(Yt, alpha=0.2, beta=0.1, gamma=0.1, seasonal="additive")
m
MSE <- m$"SSE"/(NROW(Bike)-3)
MSE
predict(object=m, n.ahead=3,prediction.interval=T, level=.95)
MSE <- m$"SSE"/(NROW(Bike)-3)
MSE
Bike <- c(10,31,43,16,11,33,45,17,13,34,48,19,15,37,51,21)
Yt <- ts(Bike, frequency=4) #function “ts” is used to create time series
Yt
plot(Yt, xlab="Time", ylab="Sales", col="Blue")
m<- HoltWinters(Yt, alpha=0.2, beta=0.1, gamma=0.1, seasonal="additive")
m
MSE <- m$"SSE"/(NROW(Bike)-3)
MSE
predict(object=m, n.ahead=3,prediction.interval=T, level=.95)
m$SSE
d1=read.table("student-mat.csv",sep=";",header=TRUE)
setwd("D:/Git/Student-Predictive-Modelling/student")
d1=read.table("student-mat.csv",sep=";",header=TRUE)
View(d1)
colnames(d1)
sapply(fraud,class)
sapply(d1,class)
is.null(d1)
colnames(d1)
d1[colnames(d1)] <- lapply(d1[colnames(d1)], is.null())
d1[colnames(d1)] <- lapply(d1[colnames(d1)], is.null)
View(d1)
d1=read.table("student-mat.csv",sep=";",header=TRUE)
sapply(d1,class)
nullPosition = d1
nullPosition <- lapply(d1[colnames(d1)], is.null)
nullPosition = data.frame(nullPosition)
d1=read.table("student-mat.csv",sep=";",header=TRUE)
sapply(d1,class)
nullPosition = data.frame(d1)
View(nullPosition)
View(nullPosition)
nullPosition <- lapply(d1[colnames(d1)], is.null)
d1[G3]
d1["G3"]
colnames(d1)
nfolds = ceiling(d1.length/10)
foldPosition = sample(rep(1:nfolds, length.out = dim(d1)[1]))
Accuracy = replicate(nfolds,0)
d1=read.table("student-mat.csv",sep=";",header=TRUE)
d1.length = dim(d1)[1]
id = 1:d1.length
pass_fail = as.factor(d1$G3 >= 10)
d1 = data.frame(id,d1,pass_fail)
colnames(d1)
nfolds = ceiling(d1.length/10)
foldPosition = sample(rep(1:nfolds, length.out = dim(d1)[1]))
Accuracy = replicate(nfolds,0)
Recall.No = replicate(nfolds,0)
Recall.Yes = replicate(nfolds,0)
Precision.No = replicate(nfolds,0)
Precision.Yes = replicate(nfolds,0)
library(e1071)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
logreg.fits = glm(pass_fail ~ .-id-G3,data=d1, family=binomial, subset=d1.train)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
logreg.fits = glm(pass_fail ~ .-id-G3,data=d1, family=binomial, subset=d1.train)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
#Recall.No[k] <- perform[1,1]/sum(perform[,1])
#Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
#Precision.No[k] <- perform[1,1]/sum(perform[1,])
#Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
#for(k in 1:nfolds){ # k folds
k=1
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
logreg.fits = glm(pass_fail ~ .-id-G3,data=d1, family=binomial, subset=d1.train)
logreg.fits = glm(pass_fail~.-id-G3,data=d1, family=binomial, subset=d1.train)
?glm
?glm
logreg.fits = glm(pass_fail~.-id-G3,data=d1.train, family=binomial)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
logreg_model = glm(pass_fail~.-id-G3,data=d1.train, family=binomial)
summary(logreg_model)
?predict
c(1:9,11)
fitted.results <- predict(logreg_model,newdata=subset(d1.test,select=c(1:9,11)),type='response')
?subset
fitted.results <- predict(logreg_model,newdata=d1.test,type='response')
fitted.results
View(d1.test)
pred <- ifelse(fitted.results > 0.5,"Pred_Yes","Pred_No")
pred
pred <- ifelse(fitted.results > 0.5,"Pass","Fail")
pred
perform <- table(pred, d1.test$pass_fail)
perform
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Accuract[k]
Accuracy[k]
nfolds = ceiling(d1.length/10)
foldPosition = sample(rep(1:nfolds, length.out = dim(d1)[1]))
d1=read.table("student-mat.csv",sep=";",header=TRUE)
d1.length = dim(d1)[1]
id = 1:d1.length
pass_fail = as.factor(d1$G3 >= 10)
d1 = data.frame(id,d1,pass_fail)
nfolds = ceiling(d1.length/10)
foldPosition = sample(rep(1:nfolds, length.out = dim(d1)[1]))
Accuracy = replicate(nfolds,0)
Recall.No = replicate(nfolds,0)
Recall.Yes = replicate(nfolds,0)
Precision.No = replicate(nfolds,0)
Precision.Yes = replicate(nfolds,0)
library(e1071)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
logreg_model = glm(pass_fail~.-id-G3,data=d1.train, family=binomial)
summary(logreg_model)
fitted.results <- predict(logreg_model,newdata=d1.test,type='response')
pred <- ifelse(fitted.results > 0.5,"Pass","Fail")
perform <- table(pred, d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
Accuracy
nfolds = ceiling(d1.length/10)
foldPosition = sample(rep(1:nfolds, length.out = dim(d1)[1]))
Accuracy = replicate(nfolds,0)
Recall.No = replicate(nfolds,0)
Recall.Yes = replicate(nfolds,0)
Precision.No = replicate(nfolds,0)
Precision.Yes = replicate(nfolds,0)
library(e1071)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
logreg_model = glm(pass_fail~.-id-G3,data=d1.train, family=binomial)
summary(logreg_model)
fitted.results <- predict(logreg_model,newdata=d1.test,type='response')
pred <- ifelse(fitted.results > 0.5,"Pass","Fail")
perform <- table(pred, d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
colnames(d1)
d1=read.table("student-mat.csv",sep=";",header=TRUE)
d1.length = dim(d1)[1]
id = 1:d1.length
pass_fail = as.factor(d1$G3 >= 10)
d1 = data.frame(id,d1,pass_fail)
colnames(d1)
.Primitive("ceiling")
nfolds = ceiling(d1.length/10)
foldPosition = sample(rep(1:nfolds, length.out = dim(d1)[1]))
Accuracy = replicate(nfolds,0)
Recall.No = replicate(nfolds,0)
Recall.Yes = replicate(nfolds,0)
Precision.No = replicate(nfolds,0)
Precision.Yes = replicate(nfolds,0)
library(e1071)
for(k in 1:nfolds){ # k folds
test_i = which(foldPosition == k)
d1.test = d1[test_i,]
d1.train = d1[-test_i,]
logreg_model = glm(pass_fail~.-id-G3,data=d1.train, family=binomial)
summary(logreg_model)
fitted.results <- predict(logreg_model,newdata=d1.test,type='response')
pred <- ifelse(fitted.results > 0.5,"Pass","Fail")
perform <- table(pred, d1.test$pass_fail)
Accuracy[k] <- sum(perform[1,1],perform[2,2])/sum(perform[,])
Recall.No[k] <- perform[1,1]/sum(perform[,1])
Recall.Yes[k] <- perform[2,2]/sum(perform[,2])
Precision.No[k] <- perform[1,1]/sum(perform[1,])
Precision.Yes[k] <- perform[2,2]/sum(perform[2,])
}
mean(Accuracy)
